spring.application.name=cloud-tracer-with-kafka
eureka.client.service-url.defaultZone=http://10.7.19.116:30007/eureka
#eureka.client.service-url.defaultZone=http://10.7.19.210:8762/eureka
eureka.instance.metadataMap.pod=pod01
#eureka.client.service-url.defaultZone=http://localhost:1111/eureka,http://localhost:1112/eureka
server.port=21111

#spring.zipkin.base-url=http://10.7.19.116:31094
#spring.sleuth.sampler.probability=1.0
#spring.zipkin.enabled=true
#spring.sleuth.enabled=true
#spring.zipkin.sender.type=kafka
#spring.kafka.bootstrap-servers=10.7.19.116:30025
#spring.zipkin.kafka.topic=myzipkin
kafka.bootstrapAddress=10.7.19.116:30025

cloud.trace.sender.type=kafka
#cloud.trace.url=http://10.7.19.116:31094
cloud.trace.probability=1.0
cloud.trace.enabled=true
cloud.trace.kafka-address=10.7.19.116:30025
cloud.trace.kafka-topic=myzipkin

#spring.zipkin.sender.type=kafka
#spring.kafka.bootstrap-servers=10.7.19.116:30025
#spring.zipkin.kafka.topic=myzipkin

logging.level.root=info
spring.redis.host=10.7.19.116:30010
feign.hystrix.enabled=true


spring.rabbitmq.host=10.7.19.116
spring.rabbitmq.port=30672
#spring.rabbitmq.username=admin
spring.rabbitmq.password=admin
spring.rabbitmq.serviceName=rabbitmq-amp



zipkin.rabbit.service.routingkey=routingKeyTracing
zipkin.rabbit.service.queue=queueTracing
zipkin.rabbit.service.exchange=exchangeTracing



spring.kafka.consumer.group-id=kafka
# smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
#spring.kafka.consumer.auto-offset-reset=earliest
# enable.auto.commit:true --> 设置自动提交offset
#spring.kafka.consumer.enable-auto-commit=true
#如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
#spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer